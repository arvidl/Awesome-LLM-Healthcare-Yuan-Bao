# Large Language Models Illuminate a Progressive Pathway to Artificial Healthcare Assistant: A Review

## ðŸ”” News
<!-- - ðŸ’¥ [2023/09/15] Our survey is released! See [The Rise and Potential of Large Language Model Based Agents: A Survey](https://arxiv.org/abs/2309.07864) for the paper! -->
- âœ¨ [2023/11/03] We create this repository to maintain a paper list on LLM-based agents. More papers are coming soon!

<div align=center><img src="./assets/main.png" width="90%" /></div>

## ðŸŒŸ Introduction
With the rapid development of artificial intelligence, large language models (LLMs) have shown promising capabilities in mimicking human-level language comprehension and reasoning. This has sparked significant interest in applying LLMs to enhance various aspects of healthcare, ranging from medical education to clinical decision support. However, medicine involves multifaceted data modalities and nuanced reasoning skills, presenting challenges for integrating LLMs. 

This repository provides a comprehensive review on the applications and implications of LLMs in medicine. It begins by examining the fundamental applications of **general-purpose and specialized LLMs**, demonstrating their utilities in knowledge retrieval, research support, clinical workflow automation, and diagnostic assistance. Recognizing the inherent multimodality of medicine, the review then focuses on **multimodal LLMs**, investigating their ability to process diverse data types like medical imaging and EHRs to augment diagnostic accuracy. To address LLMsâ€™ limitations regarding personalization and complex clinical reasoning, the paper explores the emerging development of **LLM-powered autonomous agents for healthcare**. Furthermore, it summarizes the evaluation methodologies for assessing LLMsâ€™ reliability and safety in medical contexts. Overall, this review offers an extensive analysis on the transformative potential of LLMs in modern medicine. It also highlights the pivotal need for continuous optimizations and ethical oversight before these models can be effectively integrated into clinical practice.

**We sincerely value all contributions, whether through pull requests, issue reports, emails, or other forms of communication.**

## Specialized Medical LLMs

## Multimodal LLMs in Medicine
- [2023/04] **Visual Med-Alpaca: A Parameter-Efficient Biomedical LLM with Visual Capabilities** *Chang Shu et al.* [[blog](https://cambridgeltl.github.io/visual-med-alpaca/)] [[code](https://github.com/cambridgeltl/visual-med-alpaca)]
- [2023/04] **SkinGPT-4: An Interactive Dermatology Diagnostic System with Visual Large Language Model** *Juexiao Zhou et al. arXiv.* [[paper](https://arxiv.org/abs/2304.10691)] [[code](https://github.com/JoshuaChou2018/SkinGPT-4)]
- [2023/05] **XrayGLM: The first Chinese Medical Multimodal Model that Chest Radiographs Summarization** *Rongsheng Wang et al.* [[code](https://github.com/WangRongsheng/XrayGLM)]
- [2023/05] **PathAsst: Redefining Pathology through Generative Foundation AI Assistant for Pathology** *Yuxuan Sun et al. arXiv.* [[paper](https://arxiv.org/abs/2305.15072)] [[code](https://github.com/superjamessyx/Generative-Foundation-AI-Assistant-for-Pathology)]
- [2023/05] **BiomedGPT: A Unified and Generalist Biomedical Generative Pre-trained Transformer for Vision, Language, and Multimodal Tasks** *Kai Zhang et al. arXiv.* [[paper](https://arxiv.org/abs/2305.17100)] [[code](https://github.com/taokz/BiomedGPT)]
- [2023/05] **PMC-VQA: Visual Instruction Tuning for Medical Visual Question Answering** *Xiaoman Zhang et al. arXiv.* [[paper](https://arxiv.org/abs/2305.10415)] [[code](https://github.com/xiaoman-zhang/PMC-VQA)]
- [2023/06] **LLaVA-Med: Training a Large Language-and-Vision Assistant for Biomedicine in One Day** *Chunyuan Li et al. arXiv.* [[paper](https://arxiv.org/abs/2306.00890)] [[code](https://github.com/microsoft/LLaVA-Med/blob/main/README.md)]
- [2023/06] **XrayGPT: Chest Radiographs Summarization using Medical Vision-Language Models** *Omkar Thawkar et al. arXiv.* [[paper](https://arxiv.org/abs/2306.07971)] [[code](https://github.com/mbzuai-oryx/XRayGPT)]
- [2023/07] **CephGPT-4: An Interactive Multimodal Cephalometric Measurement and Diagnostic System with Visual Large Language Model** *Lei Ma et al. arXiv.* [[paper](https://arxiv.org/abs/2307.07518)]
- [2023/07] **Towards Generalist Biomedical AI** *Tao Tu et al. arXiv.* [[paper](https://arxiv.org/abs/2307.14334)] [[code](https://github.com/kyegomez/Med-PaLM)]
- [2023/07] **Med-Flamingo: a Multimodal Medical Few-shot Learner** *Michael Moor et al. arXiv.* [[paper](https://arxiv.org/abs/2307.15189)] [[code](https://github.com/snap-stanford/med-flamingo)]
- [2023/07] **Multimodal LLMs for health grounded in individual-specific data** *Anastasiya Belyaeva et al. arXiv.* [[paper](https://arxiv.org/abs/2307.09018)] [[blog](https://blog.research.google/2023/08/multimodal-medical-ai.html)]
- [2023/08] **BioMedGPT: Open Multimodal Generative Pre-trained Transformer for BioMedicine** *Yizhen Luo et al. arXiv.* [[paper](https://arxiv.org/abs/2308.09442)] [[code](https://github.com/PharMolix/OpenBioMed)]
- [2023/08] **Towards Generalist Foundation Model for Radiology by Leveraging Web-scale 2D&3D Medical Data** *Chaoyi Wu et al. arXiv.* [[paper](https://arxiv.org/abs/2308.02463)] [[code](https://github.com/chaoyi-wu/RadFM)]
- [2023/08] **ELIXR: Towards a general purpose X-ray artificial intelligence system through alignment of large language models and radiology vision encoders** *Shawn Xu et al. arXiv.* [[paper](https://arxiv.org/abs/2308.01317)]

## Acknowledgement
Our repository has been structured following [[LLM-Agent-Paper-List]](https://github.com/WooooDyy/LLM-Agent-Paper-List/tree/main).